# FaceSketch-Awesome-List [![Awesome](README.assets/badge.svg)](https://awesome.re)
### News

- [2021.08] **Deep Facial Synthesis: A New Challenge** is coming soon! [[paper](#)] [[code](#)]



## Categories:

| Related Work                                                 |
| :----------------------------------------------------------- |
| [**Handcraft Feature based Facial Sketch Synthesis**](#Handcraft-Feature-based-Facial-Sketch-Synthesis) |
| [**General Neural Style Transfer**](#General-Neural-Style-Transfer) |
| [**Deep Image-to-Image Translation**](#Deep-Image-to-Image-Translation) |
| [**Deep Image-to-Sketch Synthesis**](#Deep-Image-to-Sketch-Synthesis) |

# Towards Image-to-Sketch Synthesis

## <a name="Handcraft Feature based Facial Sketch Synthesis"></a>Handcraft Feature based Facial Sketch Synthesis

### 2018

- <a name="RS"></a>**[RS]** Random Sampling for Fast Face Sketch Synthesis (**PR**) [[paper](https://arxiv.org/pdf/1701.01911.pdf)]

### 2017

- <a name="DSM"></a>**[DSM]** Adaptive representation-based face sketch-photo synthesis (**NC**) [[paper](https://www.sciencedirect.com/science/article/abs/pii/S0925231217310032)]

- <a name="AR"></a>**[AR]** Free-Hand Sketch Synthesis with Deformable Stroke Models (**IJCV**) [[paper](https://link.springer.com/content/pdf/10.1007%2Fs11263-016-0963-9.pdf)]

### 2016

- <a name="MR"></a>**[MR]** Multiple Representations-Based Face Sketch–Photo Synthesis (**TNNLS**) [[paper](https://ieeexplore.ieee.org/document/7244234)]

### 2015

- <a name="RobustStyle"></a>**[RobustStyle]** Superpixel-Based Face Sketch–Photo Synthesis (**TCSVT**) [[paper](https://ieeexplore.ieee.org/document/7335623)]

- <a name="SPP"></a>**[SPP]** Robust Face Sketch Style Synthesis (**TIP**) [[paper](https://ieeexplore.ieee.org/document/7331298)]

### 2014

- <a name="REB"></a>**[REB]** Real-Time Exemplar-Based Face Sketch Synthesis (**ECCV**) [[paper](https://link.springer.com/content/pdf/10.1007/978-3-319-10599-4_51.pdf)]

### 2013

- <a name="SAPS"></a>**[SAPS]** Style and abstraction in portrait sketching (**TOG**) [[paper](https://dl.acm.org/doi/pdf/10.1145/2461912.2461964)]
- <a name="FESM"></a>**[FESM]** Learnable Stroke Models for Example-based Portrait Painting (**BMVC**) [[paper](http://www.bmva.org/bmvc/2013/Papers/paper0036/paper0036.pdf)]
- <a name="Transductive"></a>**[Transductive]** Transductive Face Sketch-Photo Synthesis (**TNNLS**) [[paper](https://ieeexplore.ieee.org/document/6515363)]
- <a name="CDFSL"></a>**[CDFSL]** Coupled Dictionary and Feature Space Learning with Applications to Cross-Domain Image Synthesis and Recognition (**ICCV**) [[paper](https://openaccess.thecvf.com/content_iccv_2013/papers/Huang_Coupled_Dictionary_and_2013_ICCV_paper.pdf)]

### 2012

- <a name="SCDL"></a>**[SCDL]** Semi-coupled dictionary learning with applications to image super-resolution and photo-sketch synthesis (**CVPR**) [[paper](https://ieeexplore.ieee.org/document/6247930)]
- <a name="MWF"></a>**[MWF]** Markov Weight Fields for face sketch synthesis (**CVPR**) [[paper](https://ieeexplore.ieee.org/document/6247788)]

- <a name="SR"></a>**[SR]** Face Sketch–Photo Synthesis and Retrieval Using Sparse Representation (**TCSVT**) [[paper](https://ieeexplore.ieee.org/document/6196209)]

### 2011

- <a name="LRM"></a>**[LRM]** Local Regression Model for Automatic Face Sketch Generation (**ICIG**) [[paper](https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6005598)]

- <a name="MOR"></a>**[MOR]** Face Sketch Synthesis via Multivariate Output Regression (**HCII**) [[paper](https://link.springer.com/content/pdf/10.1007/978-3-642-21602-2_60.pdf)]
- <a name="MDSR"></a>**[MDSR]** Face Sketch-Photo Synthesis under Multi-dictionary Sparse Representation Framework (**ICIG**) [[paper](https://ieeexplore.ieee.org/document/6005537)]
- <a name="SVR"></a>**[SVR]** Face sketch-photo synthesis based on support vector regression (**ICIP**) [[paper](https://ieeexplore.ieee.org/document/6115625)]

### 2010

- <a name="LPR"></a>**[LPR]** Lighting and Pose Robust Face Sketch Synthesis (**ECCV**) [[paper](https://link.springer.com/content/pdf/10.1007/978-3-642-15567-3_31.pdf)]

### 2009

- <a name="MRF"></a>**[MRF]** Face Photo-Sketch Synthesis and Recognition (**TPAMI**) [[paper](https://ieeexplore.ieee.org/document/4624272)]

### 2008

- <a name="E-HMM"></a>**[E-HMM]** Face Sketch Synthesis Algorithm Based on E-HMM and Selective Ensemble (**TCSVT**) [[paper](https://ieeexplore.ieee.org/document/4453838)]
- <a name="HCM"></a>**[HCM]** A Hierarchical Compositional Model for Face Representation and Sketching (**TPAMI**) [[paper](https://ieeexplore.ieee.org/document/4468712)]

### 2005

- <a name="Nonlinear"></a>**[Nonlinear]** A Nonlinear Approach for Face Sketch Synthesis and Recognition (**ICCV**) [[paper](http://mmlab.ie.cuhk.edu.hk/archive/2005/CVPR_face_sketch_05.pdf)]

### 2001

- <a name="EFSGNS"></a>**[EFSGNS]** Example-based facial sketch generation with non-parametric sampling (**ICCV**) [[paper](http://www.stat.ucla.edu/~sczhu/papers/Conf_2001/TBD2001_face_sketch.pdf)]



## <a name="General Neural Style Transfer"></a>General Neural Style Transfer

### 2021

- <a name="RST"></a>**[RST]** Rethinking Style Transfer: From Pixels to Parameterized Brushstrokes (**CVPR**) [[paper](https://arxiv.org/pdf/2103.17185.pdf)] [[code](https://github.com/CompVis/brushstroke-parameterized-style-transfer)]

- <a name="LPN"></a>**[LPN]** Drafting and Revision: Laplacian Pyramid Network for Fast High-Quality Artistic Style Transfer (**CVPR**) [[paper](https://openaccess.thecvf.com/content/CVPR2021/papers/Lin_Drafting_and_Revision_Laplacian_Pyramid_Network_for_Fast_High-Quality_Artistic_CVPR_2021_paper.pdf)] [[code](https://github.com/PaddlePaddle/PaddleGAN/blob/develop/docs/en_US/tutorials/lap_style.md)])

- <a name="pSp"></a>**[pSp]** Encoding in Style: A StyleGAN Encoder for Image-to-Image Translation (**CVPR**) [[paper](https://openaccess.thecvf.com/content/CVPR2021/papers/Richardson_Encoding_in_Style_A_StyleGAN_Encoder_for_Image-to-Image_Translation_CVPR_2021_paper.pdf)] [[code](https://github.com/eladrich/pixel2style2pixel)]

### 2020

- <a name="DIN"></a>**[DIN]** Dynamic Instance Normalization for Arbitrary Style Transfer (**AAAI**) [[paper](https://arxiv.org/pdf/1911.06953.pdf)]

### 2019

- <a name="LinearTransfer"></a>**[LinearTransfer]** Learning Linear Transformations for Fast Image and Video Style Transfer (**CVPR**) [[paper](https://openaccess.thecvf.com/content_CVPR_2019/papers/Li_Learning_Linear_Transformations_for_Fast_Image_and_Video_Style_Transfer_CVPR_2019_paper.pdf)] [[code](https://github.com/sunshineatnoon/LinearStyleTransfer)]

- <a name="SANet"></a>**[SANet]** Arbitrary Style Transfer With Style-Attentional Networks (**CVPR**) [[paper](https://openaccess.thecvf.com/content_CVPR_2019/papers/Park_Arbitrary_Style_Transfer_With_Style-Attentional_Networks_CVPR_2019_paper.pdf)] [[demo](https://dypark86.github.io/SANET/)]

- <a name="Image2StyleGAN"></a>**[Image2StyleGAN]** Image2StyleGAN: How to Embed Images Into the StyleGAN Latent Space? (**CVPR**) [[paper](https://openaccess.thecvf.com/content_ICCV_2019/papers/Abdal_Image2StyleGAN_How_to_Embed_Images_Into_the_StyleGAN_Latent_Space_ICCV_2019_paper.pdf)] [[code](https://github.com/zaidbhat1234/Image2StyleGAN)]

### 2018

- <a name="DFR"></a>**[DFR]** Arbitrary Style Transfer With Deep Feature Reshuffle (**CVPR**) [[paper](https://openaccess.thecvf.com/content_cvpr_2018/papers/Gu_Arbitrary_Style_Transfer_CVPR_2018_paper.pdf)] [[code](https://github.com/msracver/Style-Feature-Reshuffle)]

- <a name="CartoonGAN"></a>**[CartoonGAN]** CartoonGAN: Generative Adversarial Networks for Photo Cartoonization (**CVPR**) [[paper](https://openaccess.thecvf.com/content_cvpr_2018/papers/Chen_CartoonGAN_Generative_Adversarial_CVPR_2018_paper.pdf)] [[code](https://github.com/znxlwm/pytorch-CartoonGAN)]

- <a name="MNetwork"></a>**[MNetwork]** Neural Style Transfer via Meta Networks (**CVPR**) [[paper](https://openaccess.thecvf.com/content_cvpr_2018/papers/Shen_Neural_Style_Transfer_CVPR_2018_paper.pdf)] [[code](https://github.com/shenfalong/styletransfer)]

- <a name="Avatar-net"></a>**[Avatar-net]** Avatar-Net: Multi-Scale Zero-Shot Style Transfer by Feature Decoration (**CVPR**) [[paper](https://openaccess.thecvf.com/content_cvpr_2018/papers/Sheng_Avatar-Net_Multi-Scale_Zero-Shot_CVPR_2018_paper.pdf)] [[code](https://github.com/LucasSheng/avatar-net)]

- <a name="CFITT"></a>**[CFITT]** A Common Framework for Interactive Texture Transfer (**CVPR**) [[paper](https://openaccess.thecvf.com/content_cvpr_2018/papers/Men_A_Common_Framework_CVPR_2018_paper.pdf)] [[code](https://github.com/menyifang/CFITT)]

- <a name="SSC"></a>**[SSC]** Separating Style and Content for Generalized Style Transfer (**CVPR**) [[paper](https://openaccess.thecvf.com/content_cvpr_2018/papers/Zhang_Separating_Style_and_CVPR_2018_paper.pdf)] [[code](https://github.com/zhyxun/Separating-Style-and-Content-for-Generalized-Style-Transfer)]

- <a name="SNST"></a>**[SNST]** Stereoscopic Neural Style Transfer (**CVPR**) [[paper](https://openaccess.thecvf.com/content_cvpr_2018/papers/Chen_Stereoscopic_Neural_Style_CVPR_2018_paper.pdf)]

- <a name="CL"></a>**[CL]** The Contextual Loss for Image Transformation with Non-Aligned Data (**ECCV**) [[paper](https://openaccess.thecvf.com/content_ECCV_2018/papers/Roey_Mechrez_The_Contextual_Loss_ECCV_2018_paper.pdf)] [[code](https://github.com/roimehrez/contextualLoss)]

- <a name="SACL"></a>**[SACL]** A Style-aware Content Loss for Real-time HD Style Transfer (**ECCV**) [[paper](https://openaccess.thecvf.com/content_ECCV_2018/papers/Artsiom_Sanakoyeu_A_Style-aware_Content_ECCV_2018_paper.pdf)]

- <a name="ARF"></a>**[ARF]** Stroke Controllable Fast Style Transfer with Adaptive Receptive Fields (**ECCV**) [[paper](https://openaccess.thecvf.com/content_ECCV_2018/papers/Yongcheng_Jing_Stroke_Controllable_Fast_ECCV_2018_paper.pdf)] [[code](https://github.com/LouieYang/stroke-controllable-fast-style-transfer)]



### 2017

- <a name="ILC"></a>**[ILC]** Incorporating Long-rage Consistency in CNN-based Texture Generation (**ICLR**) [[paper](https://arxiv.org/pdf/1606.01286.pdf)] [[code](https://github.com/guillaumebrg/texture_generation)]

- <a name="CIN"></a>**[CIN]** A Learned Representation for Artistic Style (**ICLR**) [[paper](https://arxiv.org/pdf/1610.07629.pdf)] [[code](https://github.com/magenta/magenta/tree/main/magenta/models/image_stylization)]

- <a name="CPF"></a>**[CPF]** Controlling Perceptual Factors in Neural Style Transfer (**CVPR**) [[paper](https://openaccess.thecvf.com/content_cvpr_2017/papers/Gatys_Controlling_Perceptual_Factors_CVPR_2017_paper.pdf)] [[code](https://github.com/leongatys/NeuralImageSynthesis)]

- <a name="DPST"></a>**[DPST]** Deep Photo Style Transfer (**CVPR**) [[paper](https://openaccess.thecvf.com/content_cvpr_2017/papers/Luan_Deep_Photo_Style_CVPR_2017_paper.pdf)] [[code](https://github.com/luanfujun/deep-photo-styletransfer)]

- <a name="FFN"></a>**[FFN]** Diversified Texture Synthesis With Feed-Forward Networks (**CVPR**) [[paper](https://openaccess.thecvf.com/content_cvpr_2017/papers/Li_Diversified_Texture_Synthesis_CVPR_2017_paper.pdf)] [[code](https://github.com/Yijunmaverick/MultiTextureSynthesis)]

- <a name="StyleBank"></a>**[StyleBank]** StyleBank: An Explicit Representation for Neural Image Style Transfer (**CVPR**) [[paper](https://openaccess.thecvf.com/content_cvpr_2017/papers/Chen_StyleBank_An_Explicit_CVPR_2017_paper.pdf)]

- <a name="ITN"></a>**[ITN]** Improved Texture Networks: Maximizing Quality and Diversity in Feed-Forward Stylization and Texture Synthesis (**CVPR**) [[paper](https://openaccess.thecvf.com/content_cvpr_2017/papers/Ulyanov_Improved_Texture_Networks_CVPR_2017_paper.pdf)] [[code](https://github.com/DmitryUlyanov/texture_nets)]

- <a name="HDCNN"></a>**[HDCNN]** Multimodal Transfer: A Hierarchical Deep Convolutional Neural Network for Fast Artistic Style Transfer (**CVPR**) [[paper](https://openaccess.thecvf.com/content_cvpr_2017/papers/Wang_Multimodal_Transfer_A_CVPR_2017_paper.pdf)] [[code](https://github.com/fullfanta/multimodal_transfer)]

- <a name="AdaIN"></a>**[AdaIN]** Arbitrary Style Transfer in Real-Time With Adaptive Instance Normalization (**ICCV**) [[paper](https://openaccess.thecvf.com/content_ICCV_2017/papers/Huang_Arbitrary_Style_Transfer_ICCV_2017_paper.pdf)] [[code](https://github.com/xunhuang1995/AdaIN-style)]

- <a name="CI"></a>**[CI]** Characterizing and Improving Stability in Neural Style Transfer (**ICCV**) [[paper](https://openaccess.thecvf.com/content_ICCV_2017/papers/Gupta_Characterizing_and_Improving_ICCV_2017_paper.pdf)] [[code](https://github.com/jcjohnson/fast-neural-style)]

- <a name="DNLRF"></a>**[DNLRF]** Decoder Network Over Lightweight Reconstructed Feature for Fast Semantic Style Transfer (**ICCV**) [[paper](https://openaccess.thecvf.com/content_ICCV_2017/papers/Lu_Decoder_Network_Over_ICCV_2017_paper.pdf)]

- <a name="WCT"></a>**[WCT]** Universal Style Transfer via Feature Transforms (**NeurIPS**) [[paper](https://arxiv.org/pdf/1705.08086.pdf)] [[code](https://github.com/Yijunmaverick/UniversalStyleTransfer)]

- <a name="VAT-DIA"></a>**[VAT-DIA]** Visual Attribute Transfer through Deep Image Analogy (**TOG**) [[paper](https://arxiv.org/pdf/1705.01088.pdf)] [[code](https://github.com/msracver/Deep-Image-Analogy)]

### 2016

- <a name="NST"></a>**[NST]** Image Style Transfer Using Convolutional Neural Networks (**CVPR**) [[paper](XX)] [[code](https://github.com/kaishengtai/neuralart)]

- <a name="CNNMRF"></a>**[CNNMRF]** Combining Markov Random Fields and Convolutional Neural Networks for Image Synthesis (**CVPR**) [[paper](https://openaccess.thecvf.com/content_cvpr_2016/papers/Li_Combining_Markov_Random_CVPR_2016_paper.pdf)] [[code](https://github.com/chuanli11/CNNMRF)]

- <a name="FNS"></a>**[FNS]** Perceptual Losses for Real-Time Style Transfer and Super-Resolution (**ECCV**) [[paper](https://arxiv.org/pdf/1603.08155.pdf)] [[code](https://github.com/jcjohnson/fast-neural-style)]

- <a name="MGANs"></a>**[MGANs]** Precomputed Real-Time Texture Synthesis with Markovian Generative Adversarial Networks (**ECCV**) [[paper](https://arxiv.org/pdf/1604.04382.pdf)] [[code](https://github.com/chuanli11/MGANs)]

- <a name="TextureNet"></a>**[TextureNet]** Texture Networks: Feed-forward Synthesis of Textures and Stylized Images (**ICML**) [[paper](http://proceedings.mlr.press/v48/ulyanov16.pdf)] [[code](https://github.com/DmitryUlyanov/texture_nets)]

- <a name="EDSC"></a>**[EDSC]** Painting style transfer for head portraits using convolutional neural networks (**TOG**) [[paper](https://dl.acm.org/doi/pdf/10.1145/2897824.2925968)]

- <a name="FPST"></a>**[FPST]** Fast Patch-based Style Transfer of Arbitrary Style (**NeurIPSW**) [[paper](https://arxiv.org/pdf/1612.04337.pdf)] [[code](https://github.com/rtqichen/style-swap)]

### 2015

- <a name="NST"></a>**[NST]** A Neural Algorithm of Artistic Style (**arXiv**) [[paper](https://arxiv.org/pdf/1508.06576.pdf)]

## <a name="Deep Image-to-Image Translation"></a>Deep Image-to-Image Translation

### 2021

- <a name="LLS"></a>**[LLS]** Conditional Generative Modeling via Learning the Latent Space (**ICLR**) [[paper](https://arxiv.org/pdf/2010.03132.pdf)]

- <a name="GH-feat"></a>**[GH-feat]** Generative Hierarchical Features from Synthesizing Images (**CVPR**) [[paper](https://arxiv.org/pdf/2007.10379.pdf)]

- <a name="Divco"></a>**[Divco]** DivCo: Diverse Conditional Image Synthesis via Contrastive Generative Adversarial Network (**CVPR**) [[paper](https://arxiv.org/pdf/2103.07893.pdf)]

- <a name="CoCosNet v2"></a>**[CoCosNet v2]** CoCosNet v2: Full-Resolution Correspondence Learning for Image Translation (**CVPR**) [[paper](https://openaccess.thecvf.com/content/CVPR2021/papers/Zhou_CoCosNet_v2_Full-Resolution_Correspondence_Learning_for_Image_Translation_CVPR_2021_paper.pdf)]

### 2020

- <a name="UGATIT"></a>**[UGATIT]** U-GAT-IT: Unsupervised Generative Attentional Networks with Adaptive Layer-Instance Normalization for Image-to-Image Translation (**ICLR**) [[paper](https://arxiv.org/pdf/1907.10830.pdf)]

- <a name="CrossNet"></a>**[CrossNet]** CrossNet: Latent Cross-Consistency for Unpaired Image Translation (**WACV**) [[paper](https://openaccess.thecvf.com/content_WACV_2020/papers/Sendik_CrossNet_Latent_Cross-Consistency_for_Unpaired_Image_Translation_WACV_2020_paper.pdf)]

- <a name="StarGAN v2"></a>**[StarGAN v2]** StarGAN v2: Diverse Image Synthesis for Multiple Domains (**CVPR**) [[paper](https://openaccess.thecvf.com/content_CVPR_2020/papers/Choi_StarGAN_v2_Diverse_Image_Synthesis_for_Multiple_Domains_CVPR_2020_paper.pdf)]

- <a name="HiDT"></a>**[HiDT]** High-Resolution Daytime Translation Without Domain Labels (**CVPR**) [[paper](https://openaccess.thecvf.com/content_CVPR_2020/papers/Anokhin_High-Resolution_Daytime_Translation_Without_Domain_Labels_CVPR_2020_paper.pdf)]

- <a name="NICE-GAN"></a>**[NICE-GAN]** Reusing Discriminators for Encoding: Towards Unsupervised Image-to-Image Translation (**CVPR**) [[paper](https://openaccess.thecvf.com/content_CVPR_2020/papers/Chen_Reusing_Discriminators_for_Encoding_Towards_Unsupervised_Image-to-Image_Translation_CVPR_2020_paper.pdf)]

- <a name="SEAN"></a>**[SEAN]** SEAN: Image Synthesis With Semantic Region-Adaptive Normalization (**CVPR**) [[paper](https://openaccess.thecvf.com/content_CVPR_2020/papers/Zhu_SEAN_Image_Synthesis_With_Semantic_Region-Adaptive_Normalization_CVPR_2020_paper.pdf)]

- <a name="CoCosNet"></a>**[CoCosNet]** Cross-Domain Correspondence Learning for Exemplar-Based Image Translation (**CVPR**) [[paper](https://openaccess.thecvf.com/content_CVPR_2020/papers/Zhang_Cross-Domain_Correspondence_Learning_for_Exemplar-Based_Image_Translation_CVPR_2020_paper.pdf)]

- <a name="TSIT"></a>**[TSIT]** TSIT: A Simple and Versatile Framework for Image-to-Image Translation (**ECCV**) [[paper](https://arxiv.org/pdf/2007.12072.pdf)]

- <a name="DSMAP"></a>**[DSMAP]** Domain-Specific Mappings for Generative Adversarial Style Transfer (**ECCV**) [[paper](https://arxiv.org/pdf/2008.02198.pdf)]

- <a name="ACL-GAN"></a>**[ACL-GAN]** Unpaired Image-to-Image Translation using Adversarial Consistency Loss (**ECCV**) [[paper](https://arxiv.org/pdf/2003.04858.pdf)]

- <a name="DRIT++"></a>**[DRIT++]** DRIT++: Diverse Image-to-Image Translation via Disentangled Representations (**IJCV**) [[paper](https://link.springer.com/content/pdf/10.1007/s11263-019-01284-z.pdf)]

### 2019

- <a name="EGSC-IT"></a>**[EGSC-IT]** Exemplar Guided Unsupervised Image-to-Image Translation with Semantic Consistency (**ICLR**) [[paper](https://arxiv.org/pdf/1805.11145.pdf)]

- <a name="HarmonicGAN"></a>**[HarmonicGAN]** Harmonic Unpaired Image-to-image Translation (**ICLR**) [[paper](https://arxiv.org/pdf/1902.09727.pdf)]

- <a name="GDWCT"></a>**[GDWCT]** Image-To-Image Translation via Group-Wise Deep Whitening-And-Coloring Transformation (**CVPR**) [[paper](https://openaccess.thecvf.com/content_CVPR_2019/papers/Cho_Image-To-Image_Translation_via_Group-Wise_Deep_Whitening-And-Coloring_Transformation_CVPR_2019_paper.pdf)]

- <a name="SPADE"></a>**[SPADE]** Semantic Image Synthesis with Spatially-Adaptive Normalization (**CVPR**) [[paper](https://arxiv.org/pdf/1903.07291.pdf)]

- <a name="TransGaGa"></a>**[TransGaGa]** TransGaGa: Geometry-Aware Unsupervised Image-To-Image Translation (**CVPR**) [[paper](https://openaccess.thecvf.com/content_CVPR_2019/papers/Wu_TransGaGa_Geometry-Aware_Unsupervised_Image-To-Image_Translation_CVPR_2019_paper.pdf)]

- <a name="MS-GAN"></a>**[MS-GAN]** Mode Seeking Generative Adversarial Networks for Diverse Image Synthesis (**CVPR**) [[paper](https://openaccess.thecvf.com/content_CVPR_2019/papers/Mao_Mode_Seeking_Generative_Adversarial_Networks_for_Diverse_Image_Synthesis_CVPR_2019_paper.pdf)]

- <a name="Selection-GAN"></a>**[Selection-GAN]** Multi-Channel Attention Selection GAN With Cascaded Semantic Guidance for Cross-View Image Translation (**CVPR**) [[paper](https://openaccess.thecvf.com/content_CVPR_2019/papers/Tang_Multi-Channel_Attention_Selection_GAN_With_Cascaded_Semantic_Guidance_for_Cross-View_CVPR_2019_paper.pdf)]

- <a name="AttentionGAN"></a>**[AttentionGAN]** Attention-Guided Generative Adversarial Networks for Unsupervised Image-to-Image Translation (**IJCNN**) [[paper](https://ieeexplore.ieee.org/document/8851881)]

- <a name="FUNIT"></a>**[FUNIT]** Few-Shot Unsupervised Image-to-Image Translation (**ICCV**) [[paper](https://openaccess.thecvf.com/content_ICCV_2019/papers/Liu_Few-Shot_Unsupervised_Image-to-Image_Translation_ICCV_2019_paper.pdf)]

### 2018

- <a name="Pix2pixHD"></a>**[Pix2pixHD]** High-Resolution Image Synthesis and Semantic Manipulation With Conditional GANs (**CVPR**) [[paper](https://openaccess.thecvf.com/content_cvpr_2018/papers/Wang_High-Resolution_Image_Synthesis_CVPR_2018_paper.pdf)]

- <a name="DA-GAN"></a>**[DA-GAN]** DA-GAN: Instance-Level Image Translation by Deep Attention Generative Adversarial Networks (**CVPR**) [[paper](https://openaccess.thecvf.com/content_cvpr_2018/papers/Ma_DA-GAN_Instance-Level_Image_CVPR_2018_paper.pdf)]

- <a name="StarGAN"></a>**[StarGAN]** StarGAN: Unified Generative Adversarial Networks for Multi-Domain Image-to-Image Translation (**CVPR**) [[paper](https://openaccess.thecvf.com/content_cvpr_2018/papers/Choi_StarGAN_Unified_Generative_CVPR_2018_paper.pdf)]

- <a name="ModularGAN"></a>**[ModularGAN]** Modular Generative Adversarial Networks (**ECCV**) [[paper](https://openaccess.thecvf.com/content_ECCV_2018/papers/Bo_Zhao_Modular_Generative_Adversarial_ECCV_2018_paper.pdf)]

- <a name="GANimation"></a>**[GANimation]** Anatomically Coherent Facial Expression Synthesis (**ECCV**) [[paper](https://openaccess.thecvf.com/content_ECCV_2018/papers/Albert_Pumarola_Anatomically_Coherent_Facial_ECCV_2018_paper.pdf)]

- <a name="SCANs"></a>**[SCANs]** Unsupervised Image-to-Image Translation with Stacked Cycle-Consistent Adversarial Networks (**ECCV**) [[paper](https://openaccess.thecvf.com/content_ECCV_2018/papers/Minjun_Li_Unsupervised_Image-to-Image_Translation_ECCV_2018_paper.pdf)]

- <a name="MUNIT"></a>**[MUNIT]** Multimodal Unsupervised Image-to-image Translation (**ECCV**) [[paper](https://openaccess.thecvf.com/content_ECCV_2018/papers/Xun_Huang_Multimodal_Unsupervised_Image-to-image_ECCV_2018_paper.pdf)]

- <a name="Elegant"></a>**[Elegant]** ELEGANT: Exchanging Latent Encodings with GAN for Transferring Multiple Face Attributes (**ECCV**) [[paper](https://openaccess.thecvf.com/content_ECCV_2018/papers/Taihong_Xiao_ELEGANT_Exchanging_Latent_ECCV_2018_paper.pdf)]

### 2017

- <a name="Pix2pix"></a>**[Pix2pix]** Image-To-Image Translation With Conditional Adversarial Networks (**CVPR**) [[paper](https://openaccess.thecvf.com/content_cvpr_2017/papers/Isola_Image-To-Image_Translation_With_CVPR_2017_paper.pdf)]

- <a name="SisGAN"></a>**[SisGAN]** Semantic Image Synthesis via Adversarial Learning (**ICCV**) [[paper](https://openaccess.thecvf.com/content_ICCV_2017/papers/Dong_Semantic_Image_Synthesis_ICCV_2017_paper.pdf)]

- <a name="CycleGAN"></a>**[CycleGAN]** Unpaired Image-To-Image Translation Using Cycle-Consistent Adversarial Networks (**ICCV**) [[paper](https://openaccess.thecvf.com/content_ICCV_2017/papers/Zhu_Unpaired_Image-To-Image_Translation_ICCV_2017_paper.pdf)]

- <a name="DualGAN"></a>**[DualGAN]** DualGAN: Unsupervised Dual Learning for Image-To-Image Translation (**ICCV**) [[paper](https://openaccess.thecvf.com/content_ICCV_2017/papers/Yi_DualGAN_Unsupervised_Dual_ICCV_2017_paper.pdf)]

- <a name="DiscoGAN"></a>**[DiscoGAN]** Learning to Discover Cross-Domain Relations with Generative Adversarial Networks (**ICML**) [[paper](http://proceedings.mlr.press/v70/kim17a/kim17a.pdf)]

- <a name="DTN"></a>**[DTN]** Unsupervised Cross-domain Image Generation (**ICLR**) [[paper](https://arxiv.org/pdf/1611.02200.pdf)]

- <a name="BicycleGAN"></a>**[BicycleGAN]** Toward Multimodal Image-to-Image Translation (**NeurIPS**) [[paper](https://papers.nips.cc/paper/2017/file/819f46e52c25763a55cc642422644317-Paper.pdf)]

- <a name="UNIT"></a>**[UNIT]** Unsupervised Image-to-Image Translation Networks (**NeurIPS**) [[paper](https://papers.nips.cc/paper/2017/file/dc6a6489640ca02b0d42dabeb8e46bb7-Paper.pdf)]

- <a name="DistanceGAN"></a>**[DistanceGAN]** One-Sided Unsupervised Domain Mapping (**NeurIPS**) [[paper](https://papers.nips.cc/paper/2017/file/59b90e1005a220e2ebc542eb9d950b1e-Paper.pdf)]

- <a name="TriangleGAN"></a>**[TriangleGAN]** Triangle Generative Adversarial Networks (**NeurIPS**) [[paper](https://papers.nips.cc/paper/2017/file/bbeb0c1b1fd44e392c7ce2fdbd137e87-Paper.pdf)]



## <a name="Deep Image-to-Sketch Synthesis"></a>Deep Image-to-Sketch Synthesis

### 2021

- <a name="MSG-SARL"></a>**[MSG-SARL]** Multi-Scale Gradients Self-Attention Residual Learning for Face Photo-Sketch Transformation (**TIFS**) [[paper](https://ieeexplore.ieee.org/document/9225019)]

### 2020

- <a name="APDrawing++"></a>**[APDrawing++]** Line Drawings for Face Portraits from Photos using Global and Local Structure based GANs (**TPAMI**) [[paper](https://ieeexplore.ieee.org/document/9069416)]

- <a name="UPDG"></a>**[UPDG]** Unpaired Portrait Drawing Generation via Asymmetric Cycle Mapping (**CVPR**) [[paper](https://openaccess.thecvf.com/content_CVPR_2020/papers/Yi_Unpaired_Portrait_Drawing_Generation_via_Asymmetric_Cycle_Mapping_CVPR_2020_paper.pdf)]

- <a name="WCR-GAN"></a>**[WCR-GAN]** Learning to Cartoonize Using White-Box Cartoon Representations (**CVPR**) [[paper](https://openaccess.thecvf.com/content_CVPR_2020/papers/Wang_Learning_to_Cartoonize_Using_White-Box_Cartoon_Representations_CVPR_2020_paper.pdf)]

- <a name="EdgeGAN"></a>**[EdgeGAN]** SketchyCOCO: Image Generation From Freehand Scene Sketches (**CVPR**) [[paper](https://openaccess.thecvf.com/content_CVPR_2020/papers/Gao_SketchyCOCO_Image_Generation_From_Freehand_Scene_Sketches_CVPR_2020_paper.pdf)]

- <a name="DeepPS"></a>**[DeepPS]** Deep Plastic Surgery: Robust and Controllable Image Editing with Human-Drawn Sketches (**ECCV**) [[paper](https://arxiv.org/pdf/2001.02890.pdf)]

- <a name="DeepFaceDrawing"></a>**[DeepFaceDrawing]** DeepFaceDrawing: deep generation of face images from sketches (**TOG**) [[paper](https://dl.acm.org/doi/abs/10.1145/3386569.3392386)]

- <a name="CA-GAN"></a>**[CA-GAN]** Toward Realistic Face Photo-Sketch Synthesis via Composition-Aided GANs (**ITC**) [[paper](https://ieeexplore.ieee.org/document/9025751)]

- <a name="IDA-CycleGAN"></a>**[IDA-CycleGAN]** Identity-aware CycleGAN for face photo-sketch synthesis and recognition (**PR**) [[paper](https://www.sciencedirect.com/science/article/abs/pii/S0031320320300558)]

- <a name="IPAM-GAN"></a>**[IPAM-GAN]** An Identity-Preserved Model for Face Sketch-Photo Synthesis (**SPL**) [[paper](https://ieeexplore.ieee.org/document/9126135)]

- <a name="MvDT"></a>**[MvDT]** Universal Face Photo-Sketch Style Transfer via Multiview Domain Translation (**TIP**) [[paper](https://ieeexplore.ieee.org/document/9171460)]



### 2019

- <a name="PI-REC"></a>**[PI-REC]** PI-REC: Progressive Image Reconstruction Network With Edge and Color Domain (**arXiv**) [[paper](https://arxiv.org/pdf/1903.10146.pdf)]

- <a name="DLLRR"></a>**[DLLRR]** Deep Latent Low-Rank Representation for Face Sketch Synthesis (**TNNLS**) [[paper](https://ieeexplore.ieee.org/document/8621606)]

- <a name="Col-cGAN"></a>**[Col-cGAN]** A Deep Collaborative Framework for Face Photo–Sketch Synthesis (**TNNLS**) [[paper](https://ieeexplore.ieee.org/document/8621611)]

- <a name="CFSS"></a>**[CFSS]** Cascaded Face Sketch Synthesis Under Various Illuminations (**TIP**) [[paper](https://ieeexplore.ieee.org/document/8848856)]

- <a name="KT"></a>**[KT]** Face Photo-Sketch Synthesis via Knowledge Transfer (**IJCAI**) [[paper](https://www.ijcai.org/Proceedings/2019/0147.pdf)]

- <a name="im2pencil"></a>**[im2pencil]** Im2Pencil: Controllable Pencil Illustration from Photographs (**CVPR**) [[paper](https://arxiv.org/pdf/1903.08682.pdf)]

- <a name="ISF"></a>**[ISF]** Interactive Sketch & Fill: Multiclass Sketch-to-Image Translation (**ICCV**) [[paper](https://openaccess.thecvf.com/content_ICCV_2019/papers/Ghosh_Interactive_Sketch__Fill_Multiclass_Sketch-to-Image_Translation_ICCV_2019_paper.pdf)]

- <a name="APDrawing"></a>**[APDrawing]** APDrawingGAN: Generating Artistic Portrait Drawings From Face Photos With Hierarchical GANs (**CVPR**) [[paper](https://openaccess.thecvf.com/content_CVPR_2019/papers/Yi_APDrawingGAN_Generating_Artistic_Portrait_Drawings_From_Face_Photos_With_Hierarchical_CVPR_2019_paper.pdf)]

### 2018

- <a name="FSSC2F"></a>**[FSSC2F]** Face Sketch Synthesis from Coarse to Fine (**AAAI**) [[paper](https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/viewFile/16088/16357)]

- <a name="TextureGAN"></a>**[TextureGAN]** TextureGAN: Controlling Deep Image Synthesis with Texture Patches (**CVPR**) [[paper](https://openaccess.thecvf.com/content_cvpr_2018/papers/Xian_TextureGAN_Controlling_Deep_CVPR_2018_paper.pdf)]

- <a name="SCC-GAN"></a>**[SCC-GAN]** Learning to Sketch with Shortcut Cycle Consistency (**CVPR**) [[paper](https://openaccess.thecvf.com/content_cvpr_2018/papers/Song_Learning_to_Sketch_CVPR_2018_paper.pdf)]

- <a name="ContextualGAN"></a>**[ContextualGAN]** Image Generation from Sketch Constraint Using Contextual GAN (**ECCV**) [[paper](https://arxiv.org/pdf/1711.08972.pdf)]

- <a name="pGAN"></a>**[pGAN]** Robust Face Sketch Synthesis via Generative Adversarial Fusion of Priors and Parametric Sigmoid (**IJCAI**) [[paper](https://www.ijcai.org/Proceedings/2018/0162.pdf)]

- <a name="MRNF"></a>**[MRNF]** Markov Random Neural Fields for Face Sketch Synthesis (**IJCAI**) [[paper](https://www.ijcai.org/Proceedings/2018/0159.pdf)]

- <a name="PS<sup>2</sup>-MAN"></a>**[PS<sup>2</sup>-MAN]** High-Quality Facial Photo-Sketch Synthesis Using Multi-Adversarial Networks (**FG**) [[paper](https://ieeexplore.ieee.org/document/8373815)]

- <a name="DualT"></a>**[DualT]** Dual-Transfer Face Sketch–Photo Synthesis (**TIP**) [[paper](https://ieeexplore.ieee.org/document/8463611)]

- <a name="MDAL"></a>**[MDAL]** Face Sketch Synthesis by Multidomain Adversarial Learning (**TNNLS**) [[paper](https://ieeexplore.ieee.org/document/8478205)]

- <a name="FAG-GAN"></a>**[FAG-GAN]** Facial Attributes Guided Deep Sketch-to-Photo Synthesis (**WACVW**) [[paper](https://ieeexplore.ieee.org/document/8347106)]

- <a name="Geo-GAN"></a>**[Geo-GAN]** Unsupervised Facial Geometry Learning for Sketch to Photo Synthesis (**BIOSIG**) [[paper](https://ieeexplore.ieee.org/document/8552937)]

### 2017

- <a name="DGFL"></a>**[DGFL]** Deep Graphical Feature Learning for Face Sketch Synthesis (**IJCAI**) [[paper](https://www.ijcai.org/proceedings/2017/0500.pdf)]

### 2015

- <a name="FCRL"></a>**[FCRL]** End-to-End Photo-Sketch Generation via Fully Convolutional Representation Learning (**ICMR**) [[paper](https://dl.acm.org/doi/pdf/10.1145/2671188.2749321)]



